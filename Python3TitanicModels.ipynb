{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# please do not forget to put the file with data ('titanic_data.csv') exactly in the same folder as this notebook\n",
    "# or you'll have to change your path to data...\n",
    "train = pd.read_csv('titanic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a reminder - an extremely simple baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A primitive baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most probably outcome for men - \"die\"(0), for women - \"live\" (1). The baseline model is to ascribe the most probable outcome for each man/ woman. This model is correct for 233 women and 468 men. The total accuracy is (233+468)/891 = 78.676%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Preprocessing and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's log-transform Fare. We add 1 to deal with those who didn't pay at all\n",
    "# I could try to find the \"group\" tickets using repeated ticket numbers, but not this time \n",
    "\n",
    "train[\"Fare\"] = np.log(train[\"Fare\"] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabin seems the worst variable - 687 missing. My first reaction was to cast it away. We can hardly impute something reasonable. Then I thought - maybe it was a matter of procedure - rich got more attention while boarding and their cabin number was registered. It could be a \"proxy\" for passenger's well-being. Then I found this tutorial:\n",
    "\n",
    "https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n",
    "\n",
    "\n",
    "\"Each Cabin starts with a letter. I bet this letter is much more important than the number that follows, let's slice it off.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# borrowed from:\n",
    "# https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n",
    "\n",
    "def simplify_cabins(df):\n",
    "    # no docstring or any other comment - I reproduce the function as it was in the above reference\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = simplify_cabins(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data set is tiny and the most variables are hardly informative, I'll extract one more feature from passenger's names. Of course, names themselves do not help in survival, but if we look closer, we'll see the Titles which reflect socio-cultural status of a person - can this be useful? Let's try! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex       female  male\n",
       "Title                 \n",
       "Capt           0     1\n",
       "Col            0     2\n",
       "Countess       1     0\n",
       "Don            0     1\n",
       "Dr             1     6\n",
       "Jonkheer       0     1\n",
       "Lady           1     0\n",
       "Major          0     2\n",
       "Master         0    40\n",
       "Miss         182     0\n",
       "Mlle           2     0\n",
       "Mme            1     0\n",
       "Mr             0   517\n",
       "Mrs          125     0\n",
       "Ms             1     0\n",
       "Rev            0     6\n",
       "Sir            0     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# borrowed from:\n",
    "# https://www.kaggle.com/sinakhorami/titanic-best-working-classifier\n",
    "\n",
    "import re as re\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "train[\"Title\"] = train[\"Name\"].apply(get_title)\n",
    "\n",
    "pd.crosstab(train['Title'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].replace('Mlle', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Ms', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Mme', 'Miss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rare</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex     female  male\n",
       "Title               \n",
       "Master       0    40\n",
       "Miss       186     0\n",
       "Mr           0   517\n",
       "Mrs        125     0\n",
       "Rare         3    20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train['Title'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket      Fare Cabin Embarked Title  \n",
       "61   female  38.0      0      0  113572  4.394449     B      NaN  Miss  \n",
       "829  female  62.0      0      0  113572  4.394449     B      NaN   Mrs  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[pd.isnull(train['Embarked']) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[[61, 829], \"Embarked\"] = \"S\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can safely drop the useless variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.246893</td>\n",
       "      <td>N</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.967694</td>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.094446</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>Master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.495954</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.436268</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch      Fare Cabin Embarked  \\\n",
       "0         0       3    male  22.0      1      0  2.110213     N        S   \n",
       "1         1       1  female  38.0      1      0  4.280593     C        C   \n",
       "2         1       3  female  26.0      0      0  2.188856     N        S   \n",
       "3         1       1  female  35.0      1      0  3.990834     C        S   \n",
       "4         0       3    male  35.0      0      0  2.202765     N        S   \n",
       "5         0       3    male   NaN      0      0  2.246893     N        Q   \n",
       "6         0       1    male  54.0      0      0  3.967694     E        S   \n",
       "7         0       3    male   2.0      3      1  3.094446     N        S   \n",
       "8         1       3  female  27.0      0      2  2.495954     N        S   \n",
       "9         1       2  female  14.0      1      0  3.436268     N        C   \n",
       "\n",
       "    Title  \n",
       "0      Mr  \n",
       "1     Mrs  \n",
       "2    Miss  \n",
       "3     Mrs  \n",
       "4      Mr  \n",
       "5      Mr  \n",
       "6      Mr  \n",
       "7  Master  \n",
       "8     Mrs  \n",
       "9     Mrs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's introduce one more feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"FamSize\"]=train['SibSp'] + train[\"Parch\"] +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a linear combination of two other features which might be a problem, at least in interpreting the importance of various feature. But it may be relevant to survival:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xfd236aadd8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb29dJq74ywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfd235c8240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"FamSize\", data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sexConv(s):\n",
    "    # s is a string with just 2 values - \"male\" or \"female\"\n",
    "    if s == \"male\":\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.Sex = train.Sex.apply(lambda ss: sexConv(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns = [\"Embarked\", \"Cabin\", \"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 25 columns):\n",
      "Survived        891 non-null int64\n",
      "Pclass          891 non-null int64\n",
      "Sex             891 non-null int64\n",
      "Age             714 non-null float64\n",
      "SibSp           891 non-null int64\n",
      "Parch           891 non-null int64\n",
      "Fare            891 non-null float64\n",
      "FamSize         891 non-null int64\n",
      "Embarked_C      891 non-null uint8\n",
      "Embarked_Q      891 non-null uint8\n",
      "Embarked_S      891 non-null uint8\n",
      "Cabin_A         891 non-null uint8\n",
      "Cabin_B         891 non-null uint8\n",
      "Cabin_C         891 non-null uint8\n",
      "Cabin_D         891 non-null uint8\n",
      "Cabin_E         891 non-null uint8\n",
      "Cabin_F         891 non-null uint8\n",
      "Cabin_G         891 non-null uint8\n",
      "Cabin_N         891 non-null uint8\n",
      "Cabin_T         891 non-null uint8\n",
      "Title_Master    891 non-null uint8\n",
      "Title_Miss      891 non-null uint8\n",
      "Title_Mr        891 non-null uint8\n",
      "Title_Mrs       891 non-null uint8\n",
      "Title_Rare      891 non-null uint8\n",
      "dtypes: float64(2), int64(6), uint8(17)\n",
      "memory usage: 70.6 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing \"Age\" Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use to different strategies:\n",
    "\n",
    "1. Impute the data using mean and std.dev\n",
    "\n",
    "2. Transform \"Age\" into several categories, one of which represents the missing values. The latter approach will miss \"order\" of age groups as Python has no ordered factor (categorical) variables. This was the reason why I kept \"Pclass\" as intergers, by the way, rather than transform 1, 2 and 3rd classes in categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'll need two identical copies of the data set:\n",
    "\n",
    "train1 = train.copy(deep=True)\n",
    "train2 = train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1[\"Age\"] = (train1[\"Age\"] - train1[\"Age\"].mean())/(train1[\"Age\"].std()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need a trick.\n",
    "\n",
    "Problem: If I use train1.fillna(np.random.normal(loc=0.0, scale=1.0)) , it'll call the random generator only once and fill all the missing values with this same value. This is definitely not what I want.\n",
    "\n",
    "\n",
    "Solution: Instead, I'll first fill all missing \"Age\" data with some huge number (999999) and then replace it with a random variable - one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ageConv(a):\n",
    "    # a is a numeric value or NaN - missing value, replaced by 999999.0\n",
    "    # returns the same numeric value or generates a random normal value if a was missing the replaced\n",
    "    if a == 999999.0:\n",
    "        return np.random.normal(loc=0.0, scale=1.0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamSize</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_N</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>2.962246</td>\n",
       "      <td>1.904602</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035915</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.771044</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.044893</td>\n",
       "      <td>0.208754</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.025814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.998723</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.969048</td>\n",
       "      <td>1.613459</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186182</td>\n",
       "      <td>0.119973</td>\n",
       "      <td>0.066890</td>\n",
       "      <td>0.420397</td>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.207186</td>\n",
       "      <td>0.406647</td>\n",
       "      <td>0.493796</td>\n",
       "      <td>0.347485</td>\n",
       "      <td>0.158668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.234246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.598845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.187218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.048127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.737881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.462699</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.240917</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Sex         Age       SibSp       Parch  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.383838    2.308642    0.352413    0.014197    0.523008    0.381594   \n",
       "std      0.486592    0.836071    0.477990    0.998723    1.102743    0.806057   \n",
       "min      0.000000    1.000000    0.000000   -3.234246    0.000000    0.000000   \n",
       "25%      0.000000    2.000000    0.000000   -0.598845    0.000000    0.000000   \n",
       "50%      0.000000    3.000000    0.000000   -0.048127    0.000000    0.000000   \n",
       "75%      1.000000    3.000000    1.000000    0.640270    1.000000    0.000000   \n",
       "max      1.000000    3.000000    1.000000    3.462699    8.000000    6.000000   \n",
       "\n",
       "             Fare     FamSize  Embarked_C  Embarked_Q     ...         Cabin_E  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000     ...      891.000000   \n",
       "mean     2.962246    1.904602    0.188552    0.086420     ...        0.035915   \n",
       "std      0.969048    1.613459    0.391372    0.281141     ...        0.186182   \n",
       "min      0.000000    1.000000    0.000000    0.000000     ...        0.000000   \n",
       "25%      2.187218    1.000000    0.000000    0.000000     ...        0.000000   \n",
       "50%      2.737881    1.000000    0.000000    0.000000     ...        0.000000   \n",
       "75%      3.465736    2.000000    0.000000    0.000000     ...        0.000000   \n",
       "max      6.240917   11.000000    1.000000    1.000000     ...        1.000000   \n",
       "\n",
       "          Cabin_F     Cabin_G     Cabin_N     Cabin_T  Title_Master  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000    891.000000   \n",
       "mean     0.014590    0.004489    0.771044    0.001122      0.044893   \n",
       "std      0.119973    0.066890    0.420397    0.033501      0.207186   \n",
       "min      0.000000    0.000000    0.000000    0.000000      0.000000   \n",
       "25%      0.000000    0.000000    1.000000    0.000000      0.000000   \n",
       "50%      0.000000    0.000000    1.000000    0.000000      0.000000   \n",
       "75%      0.000000    0.000000    1.000000    0.000000      0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000      1.000000   \n",
       "\n",
       "       Title_Miss    Title_Mr   Title_Mrs  Title_Rare  \n",
       "count  891.000000  891.000000  891.000000  891.000000  \n",
       "mean     0.208754    0.580247    0.140292    0.025814  \n",
       "std      0.406647    0.493796    0.347485    0.158668  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    1.000000    0.000000    0.000000  \n",
       "75%      0.000000    1.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1024)\n",
    "train1.fillna(999999, inplace = True)\n",
    "train1.Age = train1.Age.apply(lambda x: ageConv(x))\n",
    "train1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. Due to imputation, Age.mean() slightly moved from 0.0, but not much. Age.std() is virtually 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# borrowed from:\n",
    "# https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n",
    "\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 90)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2 = simplify_ages(train2)\n",
    "train2 = pd.get_dummies(train2, columns = [\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived           0\n",
       "Pclass             0\n",
       "Sex                0\n",
       "SibSp              0\n",
       "Parch              0\n",
       "Fare               0\n",
       "FamSize            0\n",
       "Embarked_C         0\n",
       "Embarked_Q         0\n",
       "Embarked_S         0\n",
       "Cabin_A            0\n",
       "Cabin_B            0\n",
       "Cabin_C            0\n",
       "Cabin_D            0\n",
       "Cabin_E            0\n",
       "Cabin_F            0\n",
       "Cabin_G            0\n",
       "Cabin_N            0\n",
       "Cabin_T            0\n",
       "Title_Master       0\n",
       "Title_Miss         0\n",
       "Title_Mr           0\n",
       "Title_Mrs          0\n",
       "Title_Rare         0\n",
       "Age_Unknown        0\n",
       "Age_Baby           0\n",
       "Age_Child          0\n",
       "Age_Teenager       0\n",
       "Age_Student        0\n",
       "Age_Young Adult    0\n",
       "Age_Adult          0\n",
       "Age_Senior         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check that now there are no missing values\n",
    "\n",
    "train2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived        0\n",
       "Pclass          0\n",
       "Sex             0\n",
       "Age             0\n",
       "SibSp           0\n",
       "Parch           0\n",
       "Fare            0\n",
       "FamSize         0\n",
       "Embarked_C      0\n",
       "Embarked_Q      0\n",
       "Embarked_S      0\n",
       "Cabin_A         0\n",
       "Cabin_B         0\n",
       "Cabin_C         0\n",
       "Cabin_D         0\n",
       "Cabin_E         0\n",
       "Cabin_F         0\n",
       "Cabin_G         0\n",
       "Cabin_N         0\n",
       "Cabin_T         0\n",
       "Title_Master    0\n",
       "Title_Miss      0\n",
       "Title_Mr        0\n",
       "Title_Mrs       0\n",
       "Title_Rare      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/ Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from the simple. Let 20% of the data (both sets) be used as a test. First, the model is trained using a couple of simple algorithms on 80% of data, then the test data might be used to access how good each model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train1, Test1 = train_test_split(train1, test_size = 0.2)\n",
    "Train2, Test2 = train_test_split(train2, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels1 = Train1[\"Survived\"]\n",
    "train_labels2 = Train2[\"Survived\"]\n",
    "test_labels1 = Test1[\"Survived\"]\n",
    "test_labels2 = Test2[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data1 = Train1.drop(\"Survived\", axis = 1)\n",
    "train_data2 = Train2.drop(\"Survived\", axis = 1)\n",
    "test_data1 = Test1.drop(\"Survived\", axis = 1)\n",
    "test_data2 = Test2.drop(\"Survived\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start from logistic regression - although it might look old-fahioned. Next, I'll use decision tree. Both algorithms are very simple, but (partly because of their simplicity) can be easily interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing: sklearn knows nothing of data frames, so they must be transformed into matrices before using in algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_regressor = linear_model.LogisticRegression(random_state = 1)\n",
    "logistic_regressor.fit(train_data1.as_matrix(), train_labels1)\n",
    "predTrain1 = logistic_regressor.predict(train_data1.as_matrix())\n",
    "predTest1 = logistic_regressor.predict(test_data1.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8412921348314607"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(train_labels1, predTrain1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test_labels1, predTest1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! It's definitely better than the primitive baseline model (78.7%) I can also extract the parameters of the regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4402263])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regressor.intercept_ # it is not very informative, of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56221456,  1.46435149, -0.38825588, -0.3870438 , -0.2596485 ,\n",
       "         0.44529725, -0.206466  ,  0.37149956,  0.12285121, -0.05412447,\n",
       "         0.05736012,  0.22037968, -0.40258448,  0.41461872,  0.98074326,\n",
       "         0.23097897, -0.39249054, -0.39437928, -0.27440014,  1.46895166,\n",
       "         0.07900196, -1.50791427,  1.00231204, -0.60212508]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the real data science! I can see that the large positive coefficient (1.46435) corresponds to \"Sex\" == 1 (i.e. \"Female\") - it's not such a big news, however. The array of numbers is pretty difficult to analyse, it badly needs some automatic processing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.56.......Pclass\n",
      "1.46.......Sex\n",
      "-0.39.......Age\n",
      "-0.39.......SibSp\n",
      "-0.26.......Parch\n",
      "0.45.......Fare\n",
      "-0.21.......FamSize\n",
      "0.37.......Embarked_C\n",
      "0.12.......Embarked_Q\n",
      "-0.05.......Embarked_S\n",
      "0.06.......Cabin_A\n",
      "0.22.......Cabin_B\n",
      "-0.4.......Cabin_C\n",
      "0.41.......Cabin_D\n",
      "0.98.......Cabin_E\n",
      "0.23.......Cabin_F\n",
      "-0.39.......Cabin_G\n",
      "-0.39.......Cabin_N\n",
      "-0.27.......Cabin_T\n",
      "1.47.......Title_Master\n",
      "0.08.......Title_Miss\n",
      "-1.51.......Title_Mr\n",
      "1.0.......Title_Mrs\n",
      "-0.6.......Title_Rare\n"
     ]
    }
   ],
   "source": [
    "feature_importance = logistic_regressor.coef_\n",
    "feature_list = list(train_data1.columns.values)\n",
    "\n",
    "for ind in range(len(feature_list)):\n",
    "    print (str(round(feature_importance[0,ind], 2))+\".......\"+feature_list[ind] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Title_Mr is the most important feature (minus 1.51 - minus means that Mr usually died), the next is Sex (1.46). You may remember from sexConv() function that males were labeled with zeroes  and females with ones. This means that women had much better chances to survive. Title_Master (1.48) also helped to survive. Master was the name for mostly very young boys (although some masters in this data set were 11 or 12 y.o. You can check this using the command train[train[\"Title\"] ==\"Master\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, higher Pclass lowered the chances to survive (-0.56), 1st class cabins were for the rich. Similarly, some cabin numbers (E) significantly increased survival rate, while others (C, G and N - unknown) decreased it (cabins for the poor, probably)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_regressor = linear_model.LogisticRegression(random_state = 1)\n",
    "logistic_regressor.fit(train_data2.as_matrix(), train_labels2)\n",
    "predTrain2 = logistic_regressor.predict(train_data2.as_matrix())\n",
    "predTest2 = logistic_regressor.predict(test_data2.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455056179775281"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(train_labels2, predTrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81564245810055869"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test_labels2, predTest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.63.......Pclass\n",
      "1.4.......Sex\n",
      "-0.39.......SibSp\n",
      "-0.22.......Parch\n",
      "0.42.......Fare\n",
      "-0.15.......FamSize\n",
      "0.35.......Embarked_C\n",
      "0.4.......Embarked_Q\n",
      "-0.29.......Embarked_S\n",
      "0.35.......Cabin_A\n",
      "0.15.......Cabin_B\n",
      "-0.38.......Cabin_C\n",
      "0.05.......Cabin_D\n",
      "0.46.......Cabin_E\n",
      "0.27.......Cabin_F\n",
      "-0.11.......Cabin_G\n",
      "-0.33.......Cabin_N\n",
      "0.0.......Cabin_T\n",
      "1.5.......Title_Master\n",
      "0.18.......Title_Miss\n",
      "-1.28.......Title_Mr\n",
      "0.72.......Title_Mrs\n",
      "-0.67.......Title_Rare\n",
      "-0.07.......Age_Unknown\n",
      "0.94.......Age_Baby\n",
      "0.21.......Age_Child\n",
      "0.04.......Age_Teenager\n",
      "0.04.......Age_Student\n",
      "0.48.......Age_Young Adult\n",
      "-0.51.......Age_Adult\n",
      "-0.68.......Age_Senior\n"
     ]
    }
   ],
   "source": [
    "feature_importance = logistic_regressor.coef_\n",
    "feature_list = list(train_data2.columns.values)\n",
    "\n",
    "for ind in range(len(feature_list)):\n",
    "    print (str(round(feature_importance[0,ind], 2))+\".......\"+feature_list[ind] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar conclusions to the above. What is new: ages Child and Young_Adult significantly increased survival chance, ages Senior and Adult - decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use decision tree algorithm for the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfTree = tree.DecisionTreeClassifier(random_state=1, max_depth = 3, min_samples_leaf = 3)\n",
    "clfTree.fit(train_data1.as_matrix(), train_labels1)\n",
    "predTrain1 = clfTree.predict(train_data1.as_matrix())\n",
    "predTest1 = clfTree.predict(test_data1.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8441011235955056"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(train_labels1, predTrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test_labels1, predTest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13838877,  0.        ,  0.01107914,  0.        ,  0.        ,\n",
       "        0.05514219,  0.09219251,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.64214728,  0.        ,  0.06105011])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfTree.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree uses several parameters for making a prediction. Others factors are not used (and have zero values for feature importance). Note that the shape of clfTree.feature_importances_ is different from logistic_regressor.coef_. Why? - who knows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.......Pclass\n",
      "0.0.......Sex\n",
      "0.01.......Age\n",
      "0.0.......SibSp\n",
      "0.0.......Parch\n",
      "0.06.......Fare\n",
      "0.09.......FamSize\n",
      "0.0.......Embarked_C\n",
      "0.0.......Embarked_Q\n",
      "0.0.......Embarked_S\n",
      "0.0.......Cabin_A\n",
      "0.0.......Cabin_B\n",
      "0.0.......Cabin_C\n",
      "0.0.......Cabin_D\n",
      "0.0.......Cabin_E\n",
      "0.0.......Cabin_F\n",
      "0.0.......Cabin_G\n",
      "0.0.......Cabin_N\n",
      "0.0.......Cabin_T\n",
      "0.0.......Title_Master\n",
      "0.0.......Title_Miss\n",
      "0.64.......Title_Mr\n",
      "0.0.......Title_Mrs\n",
      "0.06.......Title_Rare\n"
     ]
    }
   ],
   "source": [
    "feature_importance = clfTree.feature_importances_\n",
    "feature_list = list(train_data1.columns.values)\n",
    "\n",
    "for ind in range(len(feature_list)):\n",
    "    print (str(round(feature_importance[ind], 2))+\".......\"+feature_list[ind] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! The most important feature is Title_Mr (0.64). The next two features are less important: Pclass (0.14) and FamSize (0.09). These values reflect how often the tree uses the variable to split the data set. What is surprising is that the very simple model produces quite good accuracy - 80.4% for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfTree = tree.DecisionTreeClassifier(random_state=1, max_depth = 3, min_samples_leaf = 3)\n",
    "clfTree.fit(train_data2.as_matrix(), train_labels2)\n",
    "predTrain2 = clfTree.predict(train_data2.as_matrix())\n",
    "predTest2 = clfTree.predict(test_data2.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384831460674157"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(train_labels2, predTrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82681564245810057"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test_labels2, predTest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.......Pclass\n",
      "0.0.......Sex\n",
      "0.0.......SibSp\n",
      "0.0.......Parch\n",
      "0.06.......Fare\n",
      "0.09.......FamSize\n",
      "0.0.......Embarked_C\n",
      "0.0.......Embarked_Q\n",
      "0.0.......Embarked_S\n",
      "0.0.......Cabin_A\n",
      "0.0.......Cabin_B\n",
      "0.0.......Cabin_C\n",
      "0.0.......Cabin_D\n",
      "0.0.......Cabin_E\n",
      "0.0.......Cabin_F\n",
      "0.0.......Cabin_G\n",
      "0.0.......Cabin_N\n",
      "0.0.......Cabin_T\n",
      "0.0.......Title_Master\n",
      "0.0.......Title_Miss\n",
      "0.63.......Title_Mr\n",
      "0.0.......Title_Mrs\n",
      "0.07.......Title_Rare\n",
      "0.0.......Age_Unknown\n",
      "0.0.......Age_Baby\n",
      "0.0.......Age_Child\n",
      "0.0.......Age_Teenager\n",
      "0.0.......Age_Student\n",
      "0.0.......Age_Young Adult\n",
      "0.0.......Age_Adult\n",
      "0.0.......Age_Senior\n"
     ]
    }
   ],
   "source": [
    "feature_importance = clfTree.feature_importances_\n",
    "feature_list = list(train_data2.columns.values)\n",
    "\n",
    "for ind in range(len(feature_list)):\n",
    "    print (str(round(feature_importance[ind], 2))+\".......\"+feature_list[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost the same. Age is ignored, by the way..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, let's sum up! It seems that the best accuracy is achieved by decision tree for the data set with categorized Age (82.7%). But can I trust the conclusion? Is the accurcy accessment reliable? Actually, not much. The data set is tiny (891 \"observations\"). If I leave out 20% for the test set (178 \"observations\"), the test set is even smaller. So the difference between the best (82.7%) and the worst (80.45%) may be explained by pure chance - the test set better suited some of the algorithms. To tackle the issue, I should use k-fold cross-validation. For k=5, I'll do 5 attempts using 20% of the data as a mock test data set (this set is called \"validation set\") and build the model using the remaining 80%. In each attempt, I'll use different set of vaues as the validation set. Each \"observation\" will be used as a test once and for training - 4 times. Finally, I'll get 5 assessment of test accuracy (for validaion sets) which should give me the idea of how much it varies with different data sets used for the testing purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labs1 = train1[\"Survived\"]\n",
    "train_labs2 = train2[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_data1 = train1.drop(\"Survived\", axis = 1)\n",
    "tr_data2 = train2.drop(\"Survived\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfTree = tree.DecisionTreeClassifier(random_state=1, max_depth = 3, min_samples_leaf = 3)\n",
    "tree_scoring = model_selection.cross_val_score(clfTree, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84357542,  0.79888268,  0.8258427 ,  0.79213483,  0.85310734])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Now I see that accuracy varies from 79.2% to 85.3%. Let's calculate mean and std:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.822708594656   st.deviation:  0.0239656424236\n"
     ]
    }
   ],
   "source": [
    "print ('mean: ', tree_scoring.mean(), \"  st.deviation: \",  tree_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.820461332718   st.deviation:  0.0238006768479\n"
     ]
    }
   ],
   "source": [
    "clfTree = tree.DecisionTreeClassifier(random_state=1, max_depth = 3, min_samples_leaf = 3)\n",
    "tree_scoring = model_selection.cross_val_score(clfTree, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 5)\n",
    "print ('mean: ', tree_scoring.mean(), \"  st.deviation: \",  tree_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.818239249986   st.deviation:  0.0154906885612\n"
     ]
    }
   ],
   "source": [
    "logistic_regressor = linear_model.LogisticRegression(random_state = 1)\n",
    "logR_scoring = model_selection.cross_val_score(logistic_regressor, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 5)\n",
    "print ('mean: ', logR_scoring.mean(), \"  st.deviation: \",  logR_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.814862186399   st.deviation:  0.0173107602296\n"
     ]
    }
   ],
   "source": [
    "logistic_regressor = linear_model.LogisticRegression(random_state = 1)\n",
    "logR_scoring = model_selection.cross_val_score(logistic_regressor, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 5)\n",
    "print ('mean: ', logR_scoring.mean(), \"  st.deviation: \",  logR_scoring.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the better accuracy is achieved by decision tree for data with Age as a float variable (82.3%). Does this conclusion holds for ten-fold cross-validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.826088695948   st.deviation:  0.0277536819182\n"
     ]
    }
   ],
   "source": [
    "logistic_regressor = linear_model.LogisticRegression(random_state = 1)\n",
    "logR_scoring = model_selection.cross_val_score(logistic_regressor, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', logR_scoring.mean(), \"  st.deviation: \",  logR_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.816026273976   st.deviation:  0.0309078099138\n"
     ]
    }
   ],
   "source": [
    "logistic_regressor = linear_model.LogisticRegression(random_state = 1)\n",
    "logR_scoring = model_selection.cross_val_score(logistic_regressor, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', logR_scoring.mean(), \"  st.deviation: \",  logR_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.813741629781   st.deviation:  0.0281897640888\n"
     ]
    }
   ],
   "source": [
    "clfTree = tree.DecisionTreeClassifier(random_state=1, max_depth = 3, min_samples_leaf = 3)\n",
    "tree_scoring = model_selection.cross_val_score(clfTree, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', tree_scoring.mean(), \"  st.deviation: \",  tree_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.826038474634   st.deviation:  0.0289604186034\n"
     ]
    }
   ],
   "source": [
    "clfTree = tree.DecisionTreeClassifier(random_state=1, max_depth = 3, min_samples_leaf = 3)\n",
    "tree_scoring = model_selection.cross_val_score(clfTree, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', tree_scoring.mean(), \"  st.deviation: \",  tree_scoring.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the competition gets really tough! There is no statistically significant winner. The accuracy of 82.6% was achieved by the logistic regression and decision tree - but for different ways of treating the \"Age\" variable! . By the way, I could hope to improve the decision tree algorithm by playing with its parameters - tree depth (the higher it is, the more complicated patterns it should catch) and minimu size of the leaf (the higher it is, the less over-fitting occurs at the expense of te fact that it catches less details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.826088412212   st.deviation:  0.0286030628109\n"
     ]
    }
   ],
   "source": [
    "clfTree = tree.DecisionTreeClassifier(random_state=1, max_depth = 4, min_samples_leaf = 4)\n",
    "tree_scoring = model_selection.cross_val_score(clfTree, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', tree_scoring.mean(), \"  st.deviation: \",  tree_scoring.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. It turns out that the accuracy of 82.6% can also be achieved for tr_data1 , i.e. for data treating \"Age\" as a float variable. No improvement for tr_data2. Please note that I don't use default parameters for the tree algorithm. In general, tree-based algorithms usually need parameter fine-tuning for best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice feature of sklearn is that you can easily test other classification algorithms - just load its library and fit the model to the data. Let's train several other models and see if any statistically signifiacant improvement of accuracy can be achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine with linear kernel\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.830533140393   st.deviation:  0.0290239867055\n"
     ]
    }
   ],
   "source": [
    "clfSVM = svm.SVC()\n",
    "svm_scoring = model_selection.cross_val_score(clfSVM, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', svm_scoring.mean(), \"  st.deviation: \",  svm_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.830533140393   st.deviation:  0.0290239867055\n"
     ]
    }
   ],
   "source": [
    "clfSVM = svm.SVC()\n",
    "svm_scoring = model_selection.cross_val_score(clfSVM, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', svm_scoring.mean(), \"  st.deviation: \",  svm_scoring.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nearest neighbours\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.811582113268   st.deviation:  0.0416119702213\n"
     ]
    }
   ],
   "source": [
    "knn=neighbors.KNeighborsClassifier()\n",
    "knn_scoring = model_selection.cross_val_score(knn, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', knn_scoring.mean(), \"  st.deviation: \",  knn_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.810357791397   st.deviation:  0.0260153665205\n"
     ]
    }
   ],
   "source": [
    "knn=neighbors.KNeighborsClassifier()\n",
    "knn_scoring = model_selection.cross_val_score(knn, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', knn_scoring.mean(), \"  st.deviation: \",  knn_scoring.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's nothing to speak about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# also a tree based algorithm - Random Forest!\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.836138633526   st.deviation:  0.0302169819074\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=6, min_samples_leaf=3, random_state=0)\n",
    "rf_scoring = model_selection.cross_val_score(rf, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', rf_scoring.mean(), \"  st.deviation: \",  rf_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.83390392691   st.deviation:  0.0291340239136\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=5, min_samples_leaf=3, random_state=0)\n",
    "rf_scoring = model_selection.cross_val_score(rf, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', rf_scoring.mean(), \"  st.deviation: \",  rf_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.836188571104   st.deviation:  0.0268284000513\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=7, min_samples_leaf=3, random_state=0)\n",
    "rf_scoring = model_selection.cross_val_score(rf, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', rf_scoring.mean(), \"  st.deviation: \",  rf_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.831656735898   st.deviation:  0.0347272399904\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=7, min_samples_leaf=4, random_state=0)\n",
    "rf_scoring = model_selection.cross_val_score(rf, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', rf_scoring.mean(), \"  st.deviation: \",  rf_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.832755078879   st.deviation:  0.0324096118693\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=6, min_samples_leaf=4, random_state=0)\n",
    "rf_scoring = model_selection.cross_val_score(rf, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', rf_scoring.mean(), \"  st.deviation: \",  rf_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.836188571104   st.deviation:  0.0268284000513\n"
     ]
    }
   ],
   "source": [
    "# OK, this seems to be the best choice of parameters:\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=7, min_samples_leaf=3, random_state=0)\n",
    "rf_scoring = model_selection.cross_val_score(rf, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', rf_scoring.mean(), \"  st.deviation: \",  rf_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.83617608671   st.deviation:  0.0328300490192\n"
     ]
    }
   ],
   "source": [
    "# Now let's build the RF for tr_data2\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=140, max_depth=7, min_samples_leaf=5, random_state=0)\n",
    "rf_scoring = model_selection.cross_val_score(rf, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', rf_scoring.mean(), \"  st.deviation: \",  rf_scoring.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is definitely better than the two simple models (decision tree and logistic regression), its accuracy is 83.6%. By the way, number of estimators is, in fact, the number of trees which the RF builds to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One more tree-based algorithm which builds new tree so that to compensate for the error produced by the previous tree \n",
    "# rather than randomly\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.835089944388   st.deviation:  0.0417251454983\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=120, learning_rate=0.1, min_samples_leaf=4, max_depth=4, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.831731642265   st.deviation:  0.040751869058\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, min_samples_leaf=4, max_depth=4, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.835115196913   st.deviation:  0.0462143791135\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=120, learning_rate=0.1, min_samples_leaf=5, max_depth=4, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.840720690047   st.deviation:  0.0403507800322\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=120, learning_rate=0.1, min_samples_leaf=6, max_depth=4, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.832880490296   st.deviation:  0.0468253001736\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=120, learning_rate=0.1, min_samples_leaf=7, max_depth=4, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.823891442515   st.deviation:  0.0453632115591\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=120, learning_rate=0.1, min_samples_leaf=6, max_depth=5, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.833941096357   st.deviation:  0.0337408007384\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=120, learning_rate=0.1, min_samples_leaf=6, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.840720690047   st.deviation:  0.0403507800322\n"
     ]
    }
   ],
   "source": [
    "# this seems the best for tr_data1\n",
    "clfGB = GradientBoostingClassifier(n_estimators=120, learning_rate=0.1, min_samples_leaf=6, max_depth=4, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data1.as_matrix(), train_labs1, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.844028770855   st.deviation:  0.0411264644909\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.15, min_samples_leaf=5, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.836189138577   st.deviation:  0.0374850344436\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.15, min_samples_leaf=5, max_depth=4, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.84291794348   st.deviation:  0.042461498062\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.15, min_samples_leaf=6, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.838435762116   st.deviation:  0.0475222593565\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.15, min_samples_leaf=4, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.839546873227   st.deviation:  0.046997391404\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, min_samples_leaf=5, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.838461014641   st.deviation:  0.0578832706343\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.2, min_samples_leaf=5, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.846226024288   st.deviation:  0.0420883620625\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=150, learning_rate=0.15, min_samples_leaf=5, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.837287765293   st.deviation:  0.0457722070294\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=200, learning_rate=0.15, min_samples_leaf=5, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.847362104188   st.deviation:  0.0429689405355\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=140, learning_rate=0.15, min_samples_leaf=5, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.846263761208   st.deviation:  0.0413552503761\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=130, learning_rate=0.15, min_samples_leaf=5, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.847362104188   st.deviation:  0.0429689405355\n"
     ]
    }
   ],
   "source": [
    "# this seems to be the best for tr_data2\n",
    "\n",
    "clfGB = GradientBoostingClassifier(n_estimators=140, learning_rate=0.15, min_samples_leaf=5, max_depth=3, random_state=1)\n",
    "gb_scoring = model_selection.cross_val_score(clfGB, tr_data2.as_matrix(), train_labs2, scoring = 'accuracy', cv = 10)\n",
    "print ('mean: ', gb_scoring.mean(), \"  st.deviation: \",  gb_scoring.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best accuracy (84.7%) so far. What are the most important features for the algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.15, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=5,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=140, presort='auto', random_state=1,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators=140, learning_rate=0.15, min_samples_leaf=5, max_depth=3, random_state=1)\n",
    "clfGB.fit(train_data2.as_matrix(), train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06897209,  0.04465294,  0.03053972,  0.01421999,  0.47677105,\n",
       "        0.05244117,  0.00941636,  0.01377112,  0.01935555,  0.01332957,\n",
       "        0.00282104,  0.00897787,  0.00328111,  0.01073351,  0.        ,\n",
       "        0.        ,  0.01176215,  0.        ,  0.02012341,  0.00937905,\n",
       "        0.06127334,  0.00791124,  0.01182372,  0.01614527,  0.01089376,\n",
       "        0.00147694,  0.00948832,  0.02842801,  0.00959619,  0.01405064,\n",
       "        0.01836487])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfGB.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07.......Pclass\n",
      "0.04.......Sex\n",
      "0.03.......SibSp\n",
      "0.01.......Parch\n",
      "0.48.......Fare\n",
      "0.05.......FamSize\n",
      "0.01.......Embarked_C\n",
      "0.01.......Embarked_Q\n",
      "0.02.......Embarked_S\n",
      "0.01.......Cabin_A\n",
      "0.0.......Cabin_B\n",
      "0.01.......Cabin_C\n",
      "0.0.......Cabin_D\n",
      "0.01.......Cabin_E\n",
      "0.0.......Cabin_F\n",
      "0.0.......Cabin_G\n",
      "0.01.......Cabin_N\n",
      "0.0.......Cabin_T\n",
      "0.02.......Title_Master\n",
      "0.01.......Title_Miss\n",
      "0.06.......Title_Mr\n",
      "0.01.......Title_Mrs\n",
      "0.01.......Title_Rare\n",
      "0.02.......Age_Unknown\n",
      "0.01.......Age_Baby\n",
      "0.0.......Age_Child\n",
      "0.01.......Age_Teenager\n",
      "0.03.......Age_Student\n",
      "0.01.......Age_Young Adult\n",
      "0.01.......Age_Adult\n",
      "0.02.......Age_Senior\n"
     ]
    }
   ],
   "source": [
    "feature_list = list(train_data2.columns.values)\n",
    "feature_importance = clfGB.feature_importances_\n",
    "for ind in range(len(feature_list)):\n",
    "    print (str(round(feature_importance[ind], 2))+\".......\"+feature_list[ind] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite unexpectedly, the most important variable is \"Fare\"! And accuracy is  84.7%..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it mean that I could do better by working more on the \"Fare\" feature , e.g. select the group tickets and split their value between participating passengers? Possibly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to follow strategy \"Cluster than Predict\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model was pretty accurate because the data are easily split into two clusters (Males vsFemakes) with very different behaviour. So it is reasonable to split the train data set into trainM and trainF, then follow the whole programme which I executed here for train and see if there is any improvement in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all I can clearly state that Gradient Boosting is a very powerful algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
